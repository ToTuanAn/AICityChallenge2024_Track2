{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/totuanan/Workplace/AICityChallenge2024_Track2/vid2seq\n"
     ]
    }
   ],
   "source": [
    "%cd /home/totuanan/Workplace/AICityChallenge2024_Track2/vid2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['pedestrian_ckpt_path_0']= '/home/totuanan/Workplace/AICityChallenge2024_Track2/datasets/phase_checkpoints/external/pedestrian/pedestrian_phase0.pth'\n",
    "os.environ['pedestrian_ckpt_path_1']= '/home/totuanan/Workplace/AICityChallenge2024_Track2/datasets/phase_checkpoints/external/pedestrian/pedestrian_phase1.pth'\n",
    "os.environ['pedestrian_ckpt_path_2']= '/home/totuanan/Workplace/AICityChallenge2024_Track2/datasets/phase_checkpoints/external/pedestrian/pedestrian_phase2.pth'\n",
    "os.environ['pedestrian_ckpt_path_3']= '/home/totuanan/Workplace/AICityChallenge2024_Track2/datasets/phase_checkpoints/external/pedestrian/pedestrian_phase3.pth'\n",
    "os.environ['pedestrian_ckpt_path_4']= '/home/totuanan/Workplace/AICityChallenge2024_Track2/datasets/phase_checkpoints/external/pedestrian/pedestrian_phase4.pth'\n",
    "\n",
    "os.environ['vehicle_ckpt_path_0'] = '/home/totuanan/Workplace/AICityChallenge2024_Track2/datasets/phase_checkpoints/external/vehicle/vehicle_phase0.pth'\n",
    "os.environ['vehicle_ckpt_path_1'] = '/home/totuanan/Workplace/AICityChallenge2024_Track2/datasets/phase_checkpoints/external/vehicle/vehicle_phase1.pth'\n",
    "os.environ['vehicle_ckpt_path_2'] = '/home/totuanan/Workplace/AICityChallenge2024_Track2/datasets/phase_checkpoints/external/vehicle/vehicle_phase2.pth'\n",
    "os.environ['vehicle_ckpt_path_3'] = '/home/totuanan/Workplace/AICityChallenge2024_Track2/datasets/phase_checkpoints/external/vehicle/vehicle_phase3.pth'\n",
    "os.environ['vehicle_ckpt_path_4'] = '/home/totuanan/Workplace/AICityChallenge2024_Track2/datasets/phase_checkpoints/external/vehicle/vehicle_phase4.pth'\n",
    "\n",
    "os.environ['pedestrian_pred_path_0'] = 'output/pedestrian_phase_0.json'\n",
    "os.environ['pedestrian_pred_path_1'] = 'output/pedestrian_phase_1.json'\n",
    "os.environ['pedestrian_pred_path_2'] = 'output/pedestrian_phase_2.json'\n",
    "os.environ['pedestrian_pred_path_3'] = 'output/pedestrian_phase_3.json'\n",
    "os.environ['pedestrian_pred_path_4'] = 'output/pedestrian_phase_4.json'\n",
    "\n",
    "os.environ['vehicle_pred_path_0'] = 'output/vehicle_phase_0.json'\n",
    "os.environ['vehicle_pred_path_1'] = 'output/vehicle_phase_1.json'\n",
    "os.environ['vehicle_pred_path_2'] = 'output/vehicle_phase_2.json'\n",
    "os.environ['vehicle_pred_path_3'] = 'output/vehicle_phase_3.json'\n",
    "os.environ['vehicle_pred_path_4'] = 'output/vehicle_phase_4.json'\n",
    "\n",
    "os.environ['pedestrian_data_path'] ='/home/totuanan/Workplace/AICityChallenge2024_Track2/datasets/public_test/wts'\n",
    "os.environ['vehicle_data_path'] = '/home/totuanan/Workplace/AICityChallenge2024_Track2/datasets/public_test/wts'\n",
    "# os.environ['pedestrian_external_data'] = '/kaggle/input/vehicle-external-data-v0/vehicle_external_data'\n",
    "# os.environ['vehicle_external_data'] = '/kaggle/input/vehicle-external-data-v0/vehicle_external_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/totuanan/Workplace/AICityChallenge2024_Track2/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘output’: File exists\n",
      "mkdir: cannot create directory ‘data’: File exists\n",
      "/home/totuanan/Workplace/AICityChallenge2024_Track2/venv/lib/python3.8/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use_env is set by default in torchrun.\n",
      "If your script expects `--local_rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  warnings.warn(\n",
      "Processing video 0 / 664\n",
      "Processing video 100 / 664\n",
      "Processing video 200 / 664\n",
      "Processing video 300 / 664\n",
      "Processing video 400 / 664\n",
      "Processing video 500 / 664\n",
      "Processing video 600 / 664\n",
      "Phase 0 inference finished\n",
      "Processing video 0 / 664\n",
      "Processing video 100 / 664\n",
      "Processing video 200 / 664\n",
      "Processing video 300 / 664\n",
      "Processing video 400 / 664\n",
      "Processing video 500 / 664\n",
      "Processing video 600 / 664\n",
      "Phase 1 inference finished\n",
      "Processing video 0 / 664\n",
      "Processing video 100 / 664\n",
      "Processing video 200 / 664\n",
      "Processing video 300 / 664\n",
      "Processing video 400 / 664\n",
      "Processing video 500 / 664\n",
      "Processing video 600 / 664\n",
      "Phase 2 inference finished\n",
      "Processing video 0 / 664\n",
      "Processing video 100 / 664\n",
      "Processing video 200 / 664\n",
      "Processing video 300 / 664\n",
      "Processing video 400 / 664\n",
      "Processing video 500 / 664\n",
      "Processing video 600 / 664\n",
      "Phase 3 inference finished\n",
      "Processing video 0 / 664\n",
      "Processing video 100 / 664\n",
      "Processing video 200 / 664\n",
      "Processing video 300 / 664\n",
      "Processing video 400 / 664\n",
      "Processing video 500 / 664\n",
      "Processing video 600 / 664\n",
      "Phase 4 inference finished\n",
      "Rule config path:  rules_engine/configs/rule_config.yaml\n",
      "Rule mode:  pedestrian\n",
      "Finished pedestrian rules\n",
      "/home/totuanan/Workplace/AICityChallenge2024_Track2/venv/lib/python3.8/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use_env is set by default in torchrun.\n",
      "If your script expects `--local_rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  warnings.warn(\n",
      "Processing video 0 / 664\n",
      "Processing video 100 / 664\n",
      "Processing video 200 / 664\n",
      "Processing video 300 / 664\n",
      "Processing video 400 / 664\n",
      "Processing video 500 / 664\n",
      "Processing video 600 / 664\n",
      "Phase 0 inference finished\n",
      "Processing video 0 / 664\n",
      "Processing video 100 / 664\n",
      "Processing video 200 / 664\n",
      "Processing video 300 / 664\n",
      "Processing video 400 / 664\n",
      "Processing video 500 / 664\n",
      "Processing video 600 / 664\n",
      "Phase 1 inference finished\n",
      "Processing video 0 / 664\n",
      "Processing video 100 / 664\n",
      "Processing video 200 / 664\n",
      "Processing video 300 / 664\n",
      "Processing video 400 / 664\n",
      "Processing video 500 / 664\n",
      "Processing video 600 / 664\n",
      "Phase 2 inference finished\n",
      "Processing video 0 / 664\n",
      "Processing video 100 / 664\n",
      "Processing video 200 / 664\n",
      "Processing video 300 / 664\n",
      "Processing video 400 / 664\n",
      "Processing video 500 / 664\n",
      "Processing video 600 / 664\n",
      "Phase 3 inference finished\n",
      "Processing video 0 / 664\n",
      "Processing video 100 / 664\n",
      "Processing video 200 / 664\n",
      "Processing video 300 / 664\n",
      "Processing video 400 / 664\n",
      "Processing video 500 / 664\n",
      "Processing video 600 / 664\n",
      "Phase 4 inference finished\n",
      "Rule config path:  rules_engine/configs/rule_config.yaml\n",
      "Rule mode:  vehicle\n",
      "Finished vehicle rules\n"
     ]
    }
   ],
   "source": [
    "!bash ../scripts/get_submission_by_phases.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
